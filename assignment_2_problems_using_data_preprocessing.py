# -*- coding: utf-8 -*-
"""Assignment-2: Problems using Data Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jwkTnsv2EzUOma8aid_WYhbW91JfzJm8

### 1. Predicting Employee Exit

---
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('https://raw.githubusercontent.com/tranghth-lux/data-science-complete-tutorial/master/Data/HR_comma_sep.csv.txt')
df.head()

left=df[df.left==1]
len(left)

retained=df[df.left==0]
len(retained)

sns.histplot(df,x='salary',hue='left',multiple="dodge",stat='count',shrink=0.8)

sns.histplot(df,y='sales',hue='left',multiple="dodge",stat='count',shrink=0.8)

df.groupby('left').mean()

newdf=df[['satisfaction_level','average_montly_hours','promotion_last_5years','salary']]
newdf.head()

dummies=pd.get_dummies(newdf.salary,prefix='salary')

dummies.head()

newdf=pd.concat([newdf,dummies],axis=1)
newdf.drop('salary',axis=1,inplace=True)
newdf.head()

x=newdf
y=df.left

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

cross_val_score(LogisticRegression(),x,y).mean()

cross_val_score(SVC(),x,y).mean()

cross_val_score(DecisionTreeClassifier(),x,y).mean()

"""### 2. Estimate the total compensation to be provided to an employee

___



"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
files.upload()

df=pd.read_csv('train_set.csv')
len(df)

df.head()

df.drop_duplicates(inplace=True)

len(df)

df.isna().sum()

df=df[df.Union.notna()]
df=df[df.JF.notna()]

df.isna().sum()

df.dtypes

df.head()

for i in df.columns:
  print(i,':',set(list(df[i])))

group=df.groupby('OG').mean()
group

sns.scatterplot(x=df.Salaries,y=df.Total_Compensation)

group.columns

sns.scatterplot(x=df['H/D'],y=df.Total_Compensation)

sns.pointplot(y=group.index,x=group.Total_Compensation)

group2=df.groupby('YT').mean()
group2

sns.scatterplot(x=group2.index,y=group2.Total_Compensation,)

sns.scatterplot(x=df.Overtime,y=df.Total_Compensation)

df.corr()

newdf=df[['OGC','Salaries','H/D','Overtime','Total_Compensation']]
newdf.head()

dummies=pd.get_dummies(newdf.OGC,prefix='OGC')
dummies.head()

newdf=pd.concat([newdf,dummies],axis=1)
newdf.drop('OGC',axis=1,inplace=True)

newdf.head()

x=newdf.drop('Total_Compensation',axis=1)
y=newdf.Total_Compensation

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression,LinearRegression
lreg=LinearRegression()

xtrain, xtest, ytrain, ytest=train_test_split(x,y,test_size=0.2,random_state=0)

lreg.fit(xtrain,ytrain)
lreg.score(xtest,ytest)



"""### 3. Obesity Trends

---
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
files.upload()

df=pd.read_csv('obesity.csv')
df.head()

df.drop(['YearEnd', 'LocationAbbr', 'Datasource',
       'Topic', 'Data_Value_Unit', 'Data_Value_Type',
        'Data_Value_Alt', 'Data_Value_Footnote_Symbol',
       'Data_Value_Footnote','Sample_Size', 'Total',
       'Race/Ethnicity', 'GeoLocation', 'ClassID', 'TopicID', 'QuestionID',
       'DataValueTypeID', 'LocationID', 'StratificationCategory1',
       'Stratification1', 'StratificationCategoryId1', 'StratificationID1'],1,inplace=True)

df.columns

df.drop_duplicates(inplace=True)

df.isna().sum()

for i in df.columns:
  if df[i].isna().sum()>36000:
    df.drop(i,1,inplace=True)

for i in df.columns:
  if df[i].isna().sum()>0:
    df=df[df[i].notna()]

df.isna().sum()

df.head()

df.YearStart.unique()

df.Question.unique()

df=df[df.Question=='Percent of adults aged 18 years and older who have obesity']

df.drop(['Class','Question'],1,inplace=True)

df.drop_duplicates(inplace=True)
len(df)

df.reset_index(drop=True, inplace=True)

df_grouped=df.groupby(['LocationDesc','YearStart']).mean().reset_index()
df_grouped

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)

from sklearn.linear_model import LinearRegression
lr=LinearRegression()

from sklearn.preprocessing import LabelEncoder
lb=LabelEncoder()

df_grouped.rename(columns = { 'YearStart':'Year',}, inplace = True)

df_grouped['location']=lb.fit_transform(df_grouped.LocationDesc)

x=df_grouped.drop('LocationDesc',1)
y=df_grouped.Data_Value
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)

lr.fit(xtrain,ytrain)
lr.score(xtest,ytest)

"""# 4. House Price Prediction"""

import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('train.csv')
df.head()

dftest=pd.read_csv('test.csv')
dftest.head()

df.columns

dftest.columns

df.drop_duplicates(inplace=True)
len(df)

dftest.drop_duplicates(inplace=True)

Nan_dict={}
for i in df.columns:
  if df[i].isna().sum()!=0:
    Nan_dict[i]=df[i].isna().sum()
Nan_dict

dtest_Nan_dict={}
for i in dftest.columns:
  if dftest[i].isna().sum()!=0:
    dtest_Nan_dict[i]=dftest[i].isna().sum()
dtest_Nan_dict

df.info()

dftest.info()

df[['BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',
       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']][df.BsmtExposure.isna()]

fillna_NA=[
 'Alley',
 'BsmtQual',
 'BsmtCond',
 'BsmtExposure',
 'BsmtFinType1',
 'BsmtFinType2',
 'FireplaceQu',
 'GarageType',
 'GarageFinish',
 'GarageQual',
 'GarageCond',
 'PoolQC',
 'Fence',
 'MiscFeature']

modelist=['MSZoning',
 'Utilities',
 'Exterior1st',
 'Exterior2nd',
 'KitchenQual',
 'Functional',
 'SaleType']

nalist=['GarageCars',
 'GarageArea', 
 'BsmtFinSF1',
 'BsmtFinSF2',
 'BsmtUnfSF',
 'TotalBsmtSF',
 'BsmtFullBath',
 'BsmtHalfBath']

df[['YearBuilt', 'YearRemodAdd','GarageYrBlt']].corr()

df.GarageYrBlt.fillna(df.YearBuilt,inplace=True)
df.LotFrontage.fillna(df.LotFrontage.median(),inplace=True)
df.BsmtExposure[(df.BsmtExposure.isna()) & (df.BsmtCond.notna())].fillna('No',inplace=True)
for i in fillna_NA:
  df[i].fillna('NA',inplace=True)

df.Electrical.fillna(df.Electrical.mode()[0],inplace=True)
df.MasVnrType.fillna('None',inplace=True)
df.MasVnrArea.fillna(0,inplace=True)

for i in modelist:
  dftest[i].fillna(dftest[i].mode()[0],inplace=True)

for i in nalist:
  dftest[i].fillna(0,inplace=True)

dftest.GarageYrBlt.fillna(dftest.YearBuilt,inplace=True)
dftest.LotFrontage.fillna(dftest.LotFrontage.median(),inplace=True)
dftest.BsmtExposure[(dftest.BsmtExposure.isna()) & (dftest.BsmtCond.notna())].fillna('No',inplace=True)
for i in fillna_NA:
  dftest[i].fillna('NA',inplace=True)

dftest.Electrical.fillna(dftest.Electrical.mode()[0],inplace=True)
dftest.MasVnrType.fillna('None',inplace=True)
dftest.MasVnrArea.fillna(0,inplace=True)

df.info()

dftest.info()

objectlist=[]
for i in df.columns:
  if df[i].dtype=='object':
    objectlist.append(i)

objectlist_testset=[]
for i in dftest.columns:
  if dftest[i].dtype=='object':
    objectlist_testset.append(i)

objectlist==objectlist_testset

from sklearn.preprocessing import LabelEncoder
lb=LabelEncoder()

for i in objectlist:
  lb.fit(df[i])
  df[i]=lb.transform(df[i])
  dftest[i]=lb.transform(dftest[i])

x=df.drop(['Id', 'MSSubClass','SalePrice'],1)
y=df.SalePrice

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest=train_test_split(x,y, test_size=0.2,random_state=0)

from sklearn.ensemble import RandomForestRegressor
rfg=RandomForestRegressor()

from sklearn.linear_model import LinearRegression
lr=LinearRegression()

rfg.fit(xtrain,ytrain)

rfg.score(xtest,ytest)

lr.fit(xtrain,ytrain)
lr.score(xtest,ytest)

xtest=dftest.drop(['Id', 'MSSubClass',],1)

dftest['SalePrice']=rfg.predict(xtest)

output=dftest[['Id','SalePrice']]
output.to_csv('Output.csv')